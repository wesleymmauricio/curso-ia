# ğŸ¥ Sistema de AnÃ¡lise Comportamental e Reconhecimento Facial Multi-Modal

Este projeto implementa um sistema avanÃ§ado de **anÃ¡lise comportamental e reconhecimento facial**, utilizando mÃºltiplos modelos de **InteligÃªncia Artificial** para identificar pessoas, rastrear indivÃ­duos, detectar emoÃ§Ãµes e inferir atividades humanas a partir de vÃ­deos.

A execuÃ§Ã£o foi projetada para o ambiente **Google Colab**, garantindo facilidade de uso e reprodutibilidade.

---

## ğŸ“Œ VisÃ£o Geral (Overview)

O sistema realiza, de forma integrada:

- DetecÃ§Ã£o e rastreamento de pessoas
- Reconhecimento facial
- AnÃ¡lise de emoÃ§Ãµes
- ExtraÃ§Ã£o de biometria corporal
- InferÃªncia de atividades humanas

O pipeline combina modelos de visÃ£o computacional e deep learning para produzir um **vÃ­deo final anotado** e um **arquivo de resumo da anÃ¡lise**.

---

## ğŸ§° Tecnologias e Bibliotecas Utilizadas

### ğŸ”¹ Ultralytics (YOLOv8)
- DetecÃ§Ã£o e rastreamento (tracking) de pessoas e objetos
- AtribuiÃ§Ã£o de **ID Ãºnico** por indivÃ­duo para consistÃªncia entre frames

### ğŸ”¹ MediaPipe (Google)
- **Pose:** extraÃ§Ã£o de pontos do esqueleto corporal (braÃ§os, ombros, quadris, etc.)
- **FaceMesh:** mapeamento de **468 pontos faciais** para anÃ¡lise de micro-expressÃµes

### ğŸ”¹ DeepFace
- AnÃ¡lise facial profunda
- ClassificaÃ§Ã£o da **emoÃ§Ã£o dominante** (feliz, neutro, triste, etc.)

### ğŸ”¹ Dlib
- Detector facial secundÃ¡rio de alta precisÃ£o
- Uso do modelo **MMOD** para garantir recortes faciais (ROI) mais confiÃ¡veis

### ğŸ”¹ OpenCV (cv2)
- ManipulaÃ§Ã£o de vÃ­deo
- Desenho de bounding boxes e textos
- ConversÃ£o de cores (BGR â†” RGB)
- GeraÃ§Ã£o do vÃ­deo final

---

## ğŸš€ Como Executar o Projeto

### 1ï¸âƒ£ Abrir o Google Colab

Configure o ambiente conforme abaixo:

- **Linguagem:** Python 3  
- **Hardware Accelerator:** CPU  
- **VersÃ£o:** Latest  

---

### 2ï¸âƒ£ Upload dos Arquivos NecessÃ¡rios

FaÃ§a o upload manual dos seguintes arquivos no Google Colab:

#### ğŸ¬ VÃ­deo de entrada
- `unlocking_facial_recognition_diverse_activities_analysis.mp4`

> âš ï¸ **ObservaÃ§Ã£o:**  
> O vÃ­deo nÃ£o estÃ¡ disponÃ­vel no repositÃ³rio Git devido ao seu tamanho.  
> Realize o download a partir da fonte disponibilizada pela instituiÃ§Ã£o e **renomeie exatamente** conforme definido no cÃ³digo.

#### ğŸ“„ Modelo de detecÃ§Ã£o facial
- `mmod_human_face_detector.dat`

---

### 3ï¸âƒ£ InstalaÃ§Ã£o das DependÃªncias

Execute os comandos abaixo no Colab:

```bash
!pip uninstall -y mediapipe
!pip install --no-cache-dir mediapipe==0.10.14 deepface ultralytics
```

### 4ï¸âƒ£ ExecuÃ§Ã£o do CÃ³digo

O projeto possui **duas versÃµes de execuÃ§Ã£o**, cada uma com um objetivo especÃ­fico:

#### â–¶ï¸ challenger_show_colab.py
- Exibe os frames do vÃ­deo em tempo real no ambiente do **Google Colab**
- Apresenta as detecÃ§Ãµes, identificaÃ§Ãµes e emoÃ§Ãµes diretamente na tela

#### ğŸï¸ challenger_gera_video.py
- Gera um vÃ­deo final chamado:
  - `resultado_analise.mp4`
- O vÃ­deo contÃ©m toda a anÃ¡lise de reconhecimento facial e comportamental das pessoas presentes no vÃ­deo de entrada

---

## ğŸ“Š Resultados Gerados

Ao final da execuÃ§Ã£o, sÃ£o produzidos os seguintes artefatos:

- ğŸ¥ **VÃ­deo final com anÃ¡lise e reconhecimento facial**
  - Arquivo: `resultado_analise.mp4`

- ğŸ“„ **Arquivo de resumo da anÃ¡lise**
  - Arquivo: `resumo_analise.txt`

---

## ğŸ”— VÃ­deo de DemonstraÃ§Ã£o

O vÃ­deo de domonstraÃ§Ã£o tambÃ©m estÃ¡ disponÃ­vel no OneDrive:

https://1drv.ms/v/c/ff7c96d3b1848b0a/IQA7_ZoLWj3zSYob-sYmMDcDAcqYSThaTl2dBwZspPyPR_M?e=AqV2sX

AlÃ©m do video, tambÃ©m disponibilizamos o resumo gerado durante os testes resumo_analise.txt

---


